/**
 * OpenAI API å…¼å®¹æ¨¡åž‹
 */

import type { Message as ClientMessage } from 'ollama'
import type { ChatConfig, LLMConfig } from './llm.types'
import process from 'node:process'
import { isString } from '@ai/tools'
import { Ollama as Client } from 'ollama'
import { ChatConfigSchema, LLMConfigSchema } from './llm.types'

export class LLM {
  /** OpenAIå®¢æˆ·ç«¯ */
  protected client: Client
  /** LLMé…ç½® */
  protected configs: LLMConfig

  constructor(llmConf: LLMConfig) {
    try {
      this.configs = LLMConfigSchema.parse(llmConf)
      console.log('ðŸš€ this.configs:', this.configs)
      this.client = this.initOpenAI(this.configs)
    }
    catch (error) {
      console.error('ðŸš€ LLMConfig å‚æ•°é”™è¯¯:', error)
      throw error
    }
  }

  /** åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ */
  initOpenAI(llmConf: LLMConfig) {
    const { apiKey, baseURL } = llmConf

    // ç¡®ä¿APIå¯†é’¥å·²è®¾ç½®
    const key = apiKey || process.env.OPENAI_API_KEY

    // åˆ›å»ºOpenAIå®¢æˆ·ç«¯
    const ollama = new Client({
      host: baseURL,
      headers: key ? { Authorization: `Bearer ${key}` } : undefined,
    })
    return ollama
  }

  /** è°ƒç”¨OpenAI API èŠå¤©æŽ¥å£ */
  async chat(chatConf: ChatConfig) {
    const model = this.configs.model
    const cfgs = ChatConfigSchema.parse(chatConf)
    const msgs = this.formatMessages(cfgs.messages)
    console.log('ðŸš€ chat é…ç½®:', { model, cfgs, msgs })

    const stream = await this.client.chat({
      model,
      messages: msgs,
      tools: cfgs.functions,
      stream: false,
      think: cfgs.think,
    })
    let inThinking = false
    let content = ''
    let thinking = ''

    for await (const chunk of stream) {
      if (chunk.message.thinking) {
        if (!inThinking) {
          inThinking = true
          process.stdout.write('[Thinking]:\n')
        }
        process.stdout.write(chunk.message.thinking)
        thinking += chunk.message.thinking
      }
      else if (chunk.message.content) {
        if (inThinking) {
          inThinking = false
          process.stdout.write('\n\n[Answer]:\n')
        }
        process.stdout.write(chunk.message.content)
        content += chunk.message.content
      }
    }
    // æ‰“å°ç»“æŸç¬¦é˜²æ­¢åŽç»­è¾“å‡ºè¢«è¦†ç›–
    process.stdout.write('\n')

    // åˆå¹¶æ€è€ƒå’Œå›žç­”,ç”¨äºŽä¸‹ä¸€æ¬¡è¯·æ±‚ ä¾‹å¦‚: äº¤ç»™å…¶ä»–ç±»åž‹çš„agentå¤„ç†
    const new_messages = [{ role: 'assistant', thinking, content }]
  }

  formatMessages(messages: ChatConfig['messages']): ClientMessage[] {
    return messages.map((message) => {
      let content = ''
      if (isString(message.content)) {
        content = message.content
      }
      else {
        content = JSON.stringify(message.content)
      }
      return {
        role: message.role,
        content,
      }
    })
  }
}
