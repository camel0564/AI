import type { ChatRequest, LLMConfig } from './llm.types'
import process from 'node:process'
import { isString } from '@ai/tools'
import { ChatRequestSchema, LLMConfigSchema } from './llm.types'

/**
 * å¯¹å…¼å®¹ openai v1æ¥å£çš„LLMå°è£…ç±»
 * @see https://docs.ollama.com/api/openai-compatibility#%2Fv1%2Fchat%2Fcompletions
 * @see https://platform.openai.com/docs/api-reference/chat/create
 */
export class LLM {
  /** LLMé…ç½® */
  protected configs: LLMConfig
  /** å½“å‰æ­£åœ¨è¿›è¡Œçš„æµå¼è¯·æ±‚åˆ—è¡¨ï¼Œç”¨äºç®¡ç†å’Œä¸­æ­¢è¯·æ±‚ */
  protected streamingRequests: Map<string, AbortController> = new Map()

  constructor(llmConf: LLMConfig) {
    try {
      this.configs = LLMConfigSchema.parse(llmConf)
    }
    catch (error) {
      console.error('ğŸš€ LLMConfig å‚æ•°é”™è¯¯:', error)
      throw error
    }
  }

  /** è°ƒç”¨OpenAI API èŠå¤©æ¥å£ */
  async chat(request: ChatRequest) {
    /** è¯·æ±‚å‚æ•° */
    const querys = ChatRequestSchema.parse(request)
    const messages = this.formatMessages(querys)
    console.log('ğŸš€ chat è¯·æ±‚å‚æ•°:', { querys, messages })

    // const stream = await this.client.chat({
    //   ...querys,
    //   messages,
    //   tools: querys.functions,
    //   stream: false,
    //   think: querys.think,
    // })
    // let inThinking = false
    // let content = ''
    // let thinking = ''

    // for await (const chunk of stream) {
    //   if (chunk.message.thinking) {
    //     if (!inThinking) {
    //       inThinking = true
    //       process.stdout.write('[Thinking]:\n')
    //     }
    //     process.stdout.write(chunk.message.thinking)
    //     thinking += chunk.message.thinking
    //   }
    //   else if (chunk.message.content) {
    //     if (inThinking) {
    //       inThinking = false
    //       process.stdout.write('\n\n[Answer]:\n')
    //     }
    //     process.stdout.write(chunk.message.content)
    //     content += chunk.message.content
    //   }
    // }
    // // æ‰“å°ç»“æŸç¬¦é˜²æ­¢åç»­è¾“å‡ºè¢«è¦†ç›–
    // process.stdout.write('\n')

    // // åˆå¹¶æ€è€ƒå’Œå›ç­”,ç”¨äºä¸‹ä¸€æ¬¡è¯·æ±‚ ä¾‹å¦‚: äº¤ç»™å…¶ä»–ç±»å‹çš„agentå¤„ç†
    // const new_messages = [{ role: 'assistant', thinking, content }]
  }

  async sendRequest(apiPath: string, request: any) {

  }

  /**
   * æ ¼å¼åŒ–æ¶ˆæ¯ä¸ºå„ç§æ¨¡å‹éœ€è¦çš„æ ¼å¼
   */
  formatMessages(request: ChatRequest): any[] {
    return request.messages.map((message) => {
      let content = ''
      if (isString(message.content)) {
        content = message.content
      }
      else {
        content = JSON.stringify(message.content)
      }
      return {
        role: message.role,
        content,
      }
    })
  }
}
